{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamjiLee/dcgan_mnist/blob/master/dcgan_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "reKGy8JQhiNg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import network\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F3srinxG9xpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13681
        },
        "outputId": "b22b4ea5-aab6-4025-91a2-2004fc4b240e"
      },
      "cell_type": "code",
      "source": [
        "!python train.py --gpu 0 --train_dir /home/code/panhongyu/datasets/mnist --save_dir results/ --config config.yml"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "workers: 6\n",
            "display: 100\n",
            "epoches: 20\n",
            "batch_size: 128\n",
            "base_lr: 0.0002\n",
            "beta1: 0.5\n",
            "dataset: mnist\n",
            "image_size: 64\n",
            "z_size: 120\n",
            "channel_size: 1\n",
            "ngf: 128\n",
            "ndf: 128\n",
            "2019-02-24 06:31:06 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "G network structure\n",
            "generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(120, 1024, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace)\n",
            "    (12): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n",
            "D network structure\n",
            "discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (11): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "train.py:85: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  fixed_noise = Variable(fixed_noise.cuda(), volatile=True)\n",
            "epoch: [1/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 153.102s / 100iters, (1.531)\tData load 0.333s / 100iters, (0.003334)\n",
            "Loss_D = 0.12822498 (ave = 0.78957403)\n",
            "Loss_G = 4.81424570 (ave = 13.85500183)\n",
            "\n",
            "2019-02-24 06:33:42 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [1/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.229s / 100iters, (1.502)\tData load 0.015s / 100iters, (0.000154)\n",
            "Loss_D = 0.59072965 (ave = 0.62003758)\n",
            "Loss_G = 3.04098439 (ave = 9.19500290)\n",
            "\n",
            "2019-02-24 06:36:12 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [1/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.220s / 100iters, (1.502)\tData load 0.015s / 100iters, (0.000148)\n",
            "Loss_D = 0.12288987 (ave = 0.56252695)\n",
            "Loss_G = 4.01002789 (ave = 7.45952419)\n",
            "\n",
            "2019-02-24 06:38:42 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [1/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.263s / 100iters, (1.503)\tData load 0.015s / 100iters, (0.000145)\n",
            "Loss_D = 0.39880013 (ave = 0.59577225)\n",
            "Loss_G = 3.05938530 (ave = 6.41525880)\n",
            "\n",
            "2019-02-24 06:41:13 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [1/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 106.204s / 69iters, (1.539)\tData load 0.010s / 69iters, (0.000147)\n",
            "Loss_D = 0.56735492 (ave = 0.58002466)\n",
            "Loss_G = 4.92001152 (ave = 5.92292825)\n",
            "\n",
            "2019-02-24 06:42:59 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py:1334: MatplotlibDeprecationWarning: \n",
            "box-forced\n",
            "  \"2.2\", \"box-forced\", obj_type=\"keyword argument\")\n",
            "epoch: [2/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 152.836s / 100iters, (1.528)\tData load 3.056s / 100iters, (0.030560)\n",
            "Loss_D = 0.31129611 (ave = 0.64335784)\n",
            "Loss_G = 1.92300153 (ave = 2.42187018)\n",
            "\n",
            "2019-02-24 06:45:32 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [2/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.046s / 100iters, (1.500)\tData load 0.015s / 100iters, (0.000153)\n",
            "Loss_D = 0.27815706 (ave = 0.61319999)\n",
            "Loss_G = 3.22183990 (ave = 2.47449556)\n",
            "\n",
            "2019-02-24 06:48:02 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [2/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.148s / 100iters, (1.501)\tData load 0.016s / 100iters, (0.000156)\n",
            "Loss_D = 0.65486950 (ave = 0.67919415)\n",
            "Loss_G = 1.29007256 (ave = 2.45112215)\n",
            "\n",
            "2019-02-24 06:50:32 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [2/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.267s / 100iters, (1.503)\tData load 0.016s / 100iters, (0.000156)\n",
            "Loss_D = 1.87292945 (ave = 0.66692599)\n",
            "Loss_G = 6.01656294 (ave = 2.42365824)\n",
            "\n",
            "2019-02-24 06:53:02 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [2/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.633s / 69iters, (1.502)\tData load 0.011s / 69iters, (0.000153)\n",
            "Loss_D = 0.75484663 (ave = 0.67133981)\n",
            "Loss_G = 3.11731791 (ave = 2.41229675)\n",
            "\n",
            "2019-02-24 06:54:46 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [3/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 152.390s / 100iters, (1.524)\tData load 1.994s / 100iters, (0.019939)\n",
            "Loss_D = 0.91948634 (ave = 0.63201018)\n",
            "Loss_G = 4.96480656 (ave = 2.40926922)\n",
            "\n",
            "2019-02-24 06:57:18 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [3/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.645s / 100iters, (1.506)\tData load 0.016s / 100iters, (0.000157)\n",
            "Loss_D = 1.45280015 (ave = 0.59220460)\n",
            "Loss_G = 0.48442793 (ave = 2.59285271)\n",
            "\n",
            "2019-02-24 06:59:49 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [3/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.278s / 100iters, (1.503)\tData load 0.016s / 100iters, (0.000157)\n",
            "Loss_D = 0.20101580 (ave = 0.58140132)\n",
            "Loss_G = 3.00926590 (ave = 2.75351834)\n",
            "\n",
            "2019-02-24 07:02:19 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [3/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.410s / 100iters, (1.504)\tData load 0.015s / 100iters, (0.000155)\n",
            "Loss_D = 0.09696767 (ave = 0.56543453)\n",
            "Loss_G = 4.19213343 (ave = 2.84655800)\n",
            "\n",
            "2019-02-24 07:04:50 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [3/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.359s / 69iters, (1.498)\tData load 0.011s / 69iters, (0.000153)\n",
            "Loss_D = 0.36269262 (ave = 0.57006474)\n",
            "Loss_G = 4.84118891 (ave = 2.89778138)\n",
            "\n",
            "2019-02-24 07:06:33 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [4/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.632s / 100iters, (1.516)\tData load 1.855s / 100iters, (0.018553)\n",
            "Loss_D = 0.05136763 (ave = 0.41579062)\n",
            "Loss_G = 3.92584348 (ave = 3.62963768)\n",
            "\n",
            "2019-02-24 07:09:05 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [4/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.086s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000152)\n",
            "Loss_D = 0.22699976 (ave = 0.57235785)\n",
            "Loss_G = 3.86038470 (ave = 3.36313245)\n",
            "\n",
            "2019-02-24 07:11:35 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [4/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.655s / 100iters, (1.507)\tData load 0.015s / 100iters, (0.000152)\n",
            "Loss_D = 0.44994032 (ave = 0.52602870)\n",
            "Loss_G = 1.78781092 (ave = 3.45091137)\n",
            "\n",
            "2019-02-24 07:14:05 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [4/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.142s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000150)\n",
            "Loss_D = 0.09846841 (ave = 0.51171587)\n",
            "Loss_G = 4.25993204 (ave = 3.44885930)\n",
            "\n",
            "2019-02-24 07:16:35 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [4/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.414s / 69iters, (1.499)\tData load 0.011s / 69iters, (0.000159)\n",
            "Loss_D = 0.63146996 (ave = 0.52938921)\n",
            "Loss_G = 3.50106740 (ave = 3.46217427)\n",
            "\n",
            "2019-02-24 07:18:19 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [5/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.786s / 100iters, (1.518)\tData load 1.918s / 100iters, (0.019175)\n",
            "Loss_D = 0.45409781 (ave = 0.58137053)\n",
            "Loss_G = 2.65532756 (ave = 2.93389025)\n",
            "\n",
            "2019-02-24 07:20:51 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [5/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.253s / 100iters, (1.503)\tData load 0.016s / 100iters, (0.000156)\n",
            "Loss_D = 0.19604889 (ave = 0.58290423)\n",
            "Loss_G = 3.53807020 (ave = 3.04196942)\n",
            "\n",
            "2019-02-24 07:23:21 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [5/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.093s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000154)\n",
            "Loss_D = 1.13098264 (ave = 0.49083958)\n",
            "Loss_G = 1.75625408 (ave = 3.42088250)\n",
            "\n",
            "2019-02-24 07:25:51 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [5/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.287s / 100iters, (1.503)\tData load 0.016s / 100iters, (0.000156)\n",
            "Loss_D = 2.35093427 (ave = 0.53760192)\n",
            "Loss_G = 0.15856132 (ave = 3.26842629)\n",
            "\n",
            "2019-02-24 07:28:21 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [5/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.621s / 69iters, (1.502)\tData load 0.011s / 69iters, (0.000153)\n",
            "Loss_D = 0.10838342 (ave = 0.51204142)\n",
            "Loss_G = 3.52071500 (ave = 3.27932200)\n",
            "\n",
            "2019-02-24 07:30:05 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [6/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.626s / 100iters, (1.516)\tData load 1.999s / 100iters, (0.019988)\n",
            "Loss_D = 0.18206480 (ave = 0.45697355)\n",
            "Loss_G = 4.03992224 (ave = 3.53884329)\n",
            "\n",
            "2019-02-24 07:32:37 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [6/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.887s / 100iters, (1.499)\tData load 0.015s / 100iters, (0.000150)\n",
            "Loss_D = 0.17743629 (ave = 0.58527185)\n",
            "Loss_G = 3.16393852 (ave = 3.19048003)\n",
            "\n",
            "2019-02-24 07:35:06 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [6/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 149.979s / 100iters, (1.500)\tData load 0.016s / 100iters, (0.000156)\n",
            "Loss_D = 0.21074684 (ave = 0.57777376)\n",
            "Loss_G = 3.00227427 (ave = 3.07251225)\n",
            "\n",
            "2019-02-24 07:37:36 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [6/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.089s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000153)\n",
            "Loss_D = 0.38334996 (ave = 0.52944112)\n",
            "Loss_G = 0.99935621 (ave = 3.21340688)\n",
            "\n",
            "2019-02-24 07:40:06 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [6/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.204s / 69iters, (1.496)\tData load 0.010s / 69iters, (0.000150)\n",
            "Loss_D = 0.29891706 (ave = 0.55453000)\n",
            "Loss_G = 3.46284962 (ave = 3.17003985)\n",
            "\n",
            "2019-02-24 07:41:50 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [7/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.833s / 100iters, (1.518)\tData load 1.979s / 100iters, (0.019788)\n",
            "Loss_D = 0.10072631 (ave = 0.14178018)\n",
            "Loss_G = 6.07055426 (ave = 3.97728985)\n",
            "\n",
            "2019-02-24 07:44:22 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [7/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.107s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000148)\n",
            "Loss_D = 0.25663340 (ave = 0.62585902)\n",
            "Loss_G = 2.85734034 (ave = 3.22966554)\n",
            "\n",
            "2019-02-24 07:46:52 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [7/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.074s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000150)\n",
            "Loss_D = 0.21339041 (ave = 0.59966866)\n",
            "Loss_G = 2.10702896 (ave = 3.12836239)\n",
            "\n",
            "2019-02-24 07:49:22 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [7/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.112s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000151)\n",
            "Loss_D = 0.54703176 (ave = 0.59978361)\n",
            "Loss_G = 1.88905549 (ave = 3.16303830)\n",
            "\n",
            "2019-02-24 07:51:52 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [7/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.375s / 69iters, (1.498)\tData load 0.011s / 69iters, (0.000153)\n",
            "Loss_D = 0.28451151 (ave = 0.59120551)\n",
            "Loss_G = 2.96201205 (ave = 3.14567227)\n",
            "\n",
            "2019-02-24 07:53:35 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [8/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.788s / 100iters, (1.518)\tData load 2.040s / 100iters, (0.020402)\n",
            "Loss_D = 0.77790844 (ave = 0.43150178)\n",
            "Loss_G = 2.25649738 (ave = 3.73616505)\n",
            "\n",
            "2019-02-24 07:56:07 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [8/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.090s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000152)\n",
            "Loss_D = 0.39328802 (ave = 0.57253531)\n",
            "Loss_G = 2.36390996 (ave = 3.23530237)\n",
            "\n",
            "2019-02-24 07:58:37 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [8/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 149.969s / 100iters, (1.500)\tData load 0.015s / 100iters, (0.000150)\n",
            "Loss_D = 0.76643121 (ave = 0.60222906)\n",
            "Loss_G = 1.34652257 (ave = 3.07888963)\n",
            "\n",
            "2019-02-24 08:01:07 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [8/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.101s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000150)\n",
            "Loss_D = 0.12254359 (ave = 0.58506595)\n",
            "Loss_G = 4.87127972 (ave = 3.07877851)\n",
            "\n",
            "2019-02-24 08:03:37 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [8/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.226s / 69iters, (1.496)\tData load 0.010s / 69iters, (0.000150)\n",
            "Loss_D = 1.07182062 (ave = 0.55433012)\n",
            "Loss_G = 1.84360373 (ave = 3.20944631)\n",
            "\n",
            "2019-02-24 08:05:20 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [9/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.786s / 100iters, (1.518)\tData load 1.920s / 100iters, (0.019203)\n",
            "Loss_D = 0.35523111 (ave = 0.71028453)\n",
            "Loss_G = 4.28060818 (ave = 2.56353788)\n",
            "\n",
            "2019-02-24 08:07:52 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [9/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.183s / 100iters, (1.502)\tData load 0.015s / 100iters, (0.000151)\n",
            "Loss_D = 0.67370331 (ave = 0.64686296)\n",
            "Loss_G = 1.51728582 (ave = 2.79052103)\n",
            "\n",
            "2019-02-24 08:10:22 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [9/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.271s / 100iters, (1.503)\tData load 0.015s / 100iters, (0.000147)\n",
            "Loss_D = 0.22646686 (ave = 0.62266545)\n",
            "Loss_G = 3.91434216 (ave = 2.85536323)\n",
            "\n",
            "2019-02-24 08:12:53 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [9/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.138s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000147)\n",
            "Loss_D = 0.49177277 (ave = 0.56248618)\n",
            "Loss_G = 3.13474607 (ave = 3.08802465)\n",
            "\n",
            "2019-02-24 08:15:23 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [9/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.241s / 69iters, (1.496)\tData load 0.010s / 69iters, (0.000149)\n",
            "Loss_D = 0.87912512 (ave = 0.59109591)\n",
            "Loss_G = 1.19327796 (ave = 3.05380260)\n",
            "\n",
            "2019-02-24 08:17:06 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [10/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.562s / 100iters, (1.516)\tData load 1.956s / 100iters, (0.019557)\n",
            "Loss_D = 0.19004297 (ave = 0.59834689)\n",
            "Loss_G = 3.27065372 (ave = 2.89014564)\n",
            "\n",
            "2019-02-24 08:19:38 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [10/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.960s / 100iters, (1.500)\tData load 0.015s / 100iters, (0.000154)\n",
            "Loss_D = 0.10497808 (ave = 0.50877551)\n",
            "Loss_G = 4.57141542 (ave = 3.12175805)\n",
            "\n",
            "2019-02-24 08:22:08 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [10/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 149.897s / 100iters, (1.499)\tData load 0.016s / 100iters, (0.000155)\n",
            "Loss_D = 0.21084797 (ave = 0.44871598)\n",
            "Loss_G = 2.30137253 (ave = 3.33874481)\n",
            "\n",
            "2019-02-24 08:24:37 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [10/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 149.959s / 100iters, (1.500)\tData load 0.015s / 100iters, (0.000154)\n",
            "Loss_D = 0.47787115 (ave = 0.50192429)\n",
            "Loss_G = 3.68421268 (ave = 3.23276388)\n",
            "\n",
            "2019-02-24 08:27:07 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [10/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.070s / 69iters, (1.494)\tData load 0.011s / 69iters, (0.000154)\n",
            "Loss_D = 0.08712620 (ave = 0.49785309)\n",
            "Loss_G = 2.82330894 (ave = 3.20738189)\n",
            "\n",
            "2019-02-24 08:28:50 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [11/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.672s / 100iters, (1.517)\tData load 1.949s / 100iters, (0.019493)\n",
            "Loss_D = 0.50560898 (ave = 0.46208130)\n",
            "Loss_G = 2.24533486 (ave = 3.50316902)\n",
            "\n",
            "2019-02-24 08:31:22 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [11/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.985s / 100iters, (1.500)\tData load 0.015s / 100iters, (0.000154)\n",
            "Loss_D = 0.47287491 (ave = 0.53139988)\n",
            "Loss_G = 2.42840815 (ave = 3.25176037)\n",
            "\n",
            "2019-02-24 08:33:52 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [11/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.069s / 100iters, (1.501)\tData load 0.016s / 100iters, (0.000156)\n",
            "Loss_D = 1.01405573 (ave = 0.50007669)\n",
            "Loss_G = 1.56316423 (ave = 3.30569183)\n",
            "\n",
            "2019-02-24 08:36:22 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [11/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.099s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000151)\n",
            "Loss_D = 1.93131733 (ave = 0.55103960)\n",
            "Loss_G = 3.52382445 (ave = 3.17922532)\n",
            "\n",
            "2019-02-24 08:38:52 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [11/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.291s / 69iters, (1.497)\tData load 0.010s / 69iters, (0.000149)\n",
            "Loss_D = 0.07125919 (ave = 0.50320553)\n",
            "Loss_G = 4.11542749 (ave = 3.24640204)\n",
            "\n",
            "2019-02-24 08:40:36 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [12/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.492s / 100iters, (1.515)\tData load 1.959s / 100iters, (0.019594)\n",
            "Loss_D = 1.33611751 (ave = 0.50199444)\n",
            "Loss_G = 7.81422901 (ave = 3.47849551)\n",
            "\n",
            "2019-02-24 08:43:07 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [12/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.899s / 100iters, (1.499)\tData load 0.016s / 100iters, (0.000156)\n",
            "Loss_D = 0.13906987 (ave = 0.52178733)\n",
            "Loss_G = 4.09370518 (ave = 3.28928294)\n",
            "\n",
            "2019-02-24 08:45:37 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [12/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 149.914s / 100iters, (1.499)\tData load 0.015s / 100iters, (0.000152)\n",
            "Loss_D = 0.03395617 (ave = 0.36532245)\n",
            "Loss_G = 4.95403767 (ave = 3.71215242)\n",
            "\n",
            "2019-02-24 08:48:07 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [12/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 149.875s / 100iters, (1.499)\tData load 0.015s / 100iters, (0.000148)\n",
            "Loss_D = 2.01133132 (ave = 0.46138374)\n",
            "Loss_G = 2.23931694 (ave = 3.51495401)\n",
            "\n",
            "2019-02-24 08:50:37 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [12/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.062s / 69iters, (1.494)\tData load 0.011s / 69iters, (0.000154)\n",
            "Loss_D = 0.24141136 (ave = 0.50098469)\n",
            "Loss_G = 3.42311502 (ave = 3.42523333)\n",
            "\n",
            "2019-02-24 08:52:20 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [13/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.655s / 100iters, (1.517)\tData load 2.014s / 100iters, (0.020142)\n",
            "Loss_D = 0.69396895 (ave = 0.55412444)\n",
            "Loss_G = 0.88496834 (ave = 3.02080382)\n",
            "\n",
            "2019-02-24 08:54:51 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [13/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.976s / 100iters, (1.500)\tData load 0.015s / 100iters, (0.000154)\n",
            "Loss_D = 0.25063956 (ave = 0.61643375)\n",
            "Loss_G = 2.16091228 (ave = 2.98837200)\n",
            "\n",
            "2019-02-24 08:57:21 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [13/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.049s / 100iters, (1.500)\tData load 0.016s / 100iters, (0.000159)\n",
            "Loss_D = 0.61587739 (ave = 0.54151663)\n",
            "Loss_G = 1.63765311 (ave = 3.15264689)\n",
            "\n",
            "2019-02-24 08:59:51 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [13/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.103s / 100iters, (1.501)\tData load 0.016s / 100iters, (0.000158)\n",
            "Loss_D = 0.25024551 (ave = 0.55200380)\n",
            "Loss_G = 3.41931820 (ave = 3.10728254)\n",
            "\n",
            "2019-02-24 09:02:22 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [13/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.224s / 69iters, (1.496)\tData load 0.010s / 69iters, (0.000149)\n",
            "Loss_D = 0.03577948 (ave = 0.48725073)\n",
            "Loss_G = 4.68398237 (ave = 3.26660083)\n",
            "\n",
            "2019-02-24 09:04:05 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [14/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.415s / 100iters, (1.514)\tData load 1.940s / 100iters, (0.019403)\n",
            "Loss_D = 0.32002473 (ave = 0.58270984)\n",
            "Loss_G = 2.36034155 (ave = 3.27201842)\n",
            "\n",
            "2019-02-24 09:06:36 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [14/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.934s / 100iters, (1.499)\tData load 0.016s / 100iters, (0.000155)\n",
            "Loss_D = 0.06171790 (ave = 0.52088627)\n",
            "Loss_G = 3.81933308 (ave = 3.29174678)\n",
            "\n",
            "2019-02-24 09:09:06 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [14/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 149.834s / 100iters, (1.498)\tData load 0.015s / 100iters, (0.000152)\n",
            "Loss_D = 0.01625316 (ave = 0.36209935)\n",
            "Loss_G = 3.86879301 (ave = 3.74470930)\n",
            "\n",
            "2019-02-24 09:11:36 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [14/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 149.836s / 100iters, (1.498)\tData load 0.015s / 100iters, (0.000155)\n",
            "Loss_D = 0.48151588 (ave = 0.49333746)\n",
            "Loss_G = 1.54617679 (ave = 3.45869741)\n",
            "\n",
            "2019-02-24 09:14:06 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [14/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.174s / 69iters, (1.495)\tData load 0.010s / 69iters, (0.000147)\n",
            "Loss_D = 0.46680990 (ave = 0.51829339)\n",
            "Loss_G = 3.97545552 (ave = 3.37174454)\n",
            "\n",
            "2019-02-24 09:15:49 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [15/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.742s / 100iters, (1.517)\tData load 1.995s / 100iters, (0.019951)\n",
            "Loss_D = 0.53212059 (ave = 0.60673317)\n",
            "Loss_G = 6.17560291 (ave = 2.99358648)\n",
            "\n",
            "2019-02-24 09:18:21 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [15/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.049s / 100iters, (1.500)\tData load 0.015s / 100iters, (0.000155)\n",
            "Loss_D = 0.24726656 (ave = 0.61905470)\n",
            "Loss_G = 3.10799074 (ave = 2.97985409)\n",
            "\n",
            "2019-02-24 09:20:51 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [15/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.038s / 100iters, (1.500)\tData load 0.016s / 100iters, (0.000159)\n",
            "Loss_D = 0.64399040 (ave = 0.57711069)\n",
            "Loss_G = 3.11946964 (ave = 3.08691772)\n",
            "\n",
            "2019-02-24 09:23:21 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [15/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 150.086s / 100iters, (1.501)\tData load 0.015s / 100iters, (0.000153)\n",
            "Loss_D = 2.45964885 (ave = 0.55993438)\n",
            "Loss_G = 0.46403554 (ave = 3.14937666)\n",
            "\n",
            "2019-02-24 09:25:51 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [15/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.260s / 69iters, (1.497)\tData load 0.010s / 69iters, (0.000151)\n",
            "Loss_D = 0.37042648 (ave = 0.55846887)\n",
            "Loss_G = 4.68949223 (ave = 3.11636118)\n",
            "\n",
            "2019-02-24 09:27:34 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [16/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.551s / 100iters, (1.516)\tData load 1.963s / 100iters, (0.019630)\n",
            "Loss_D = 0.06510084 (ave = 0.06466814)\n",
            "Loss_G = 3.94058275 (ave = 4.45098637)\n",
            "\n",
            "2019-02-24 09:30:06 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [16/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 150.010s / 100iters, (1.500)\tData load 0.015s / 100iters, (0.000152)\n",
            "Loss_D = 0.81463706 (ave = 0.22679434)\n",
            "Loss_G = 1.67640817 (ave = 4.50758454)\n",
            "\n",
            "2019-02-24 09:32:36 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [16/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 149.795s / 100iters, (1.498)\tData load 0.016s / 100iters, (0.000156)\n",
            "Loss_D = 0.42797774 (ave = 0.35275401)\n",
            "Loss_G = 2.83288717 (ave = 3.83236008)\n",
            "\n",
            "2019-02-24 09:35:06 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [16/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 149.737s / 100iters, (1.497)\tData load 0.016s / 100iters, (0.000157)\n",
            "Loss_D = 0.14757755 (ave = 0.43200297)\n",
            "Loss_G = 3.71479726 (ave = 3.65302150)\n",
            "\n",
            "2019-02-24 09:37:35 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [16/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.081s / 69iters, (1.494)\tData load 0.010s / 69iters, (0.000151)\n",
            "Loss_D = 0.13932158 (ave = 0.43157613)\n",
            "Loss_G = 4.14259195 (ave = 3.59354981)\n",
            "\n",
            "2019-02-24 09:39:18 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [17/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.630s / 100iters, (1.516)\tData load 2.038s / 100iters, (0.020377)\n",
            "Loss_D = 0.72167051 (ave = 0.72224843)\n",
            "Loss_G = 1.51414061 (ave = 3.24534160)\n",
            "\n",
            "2019-02-24 09:41:50 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [17/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.897s / 100iters, (1.499)\tData load 0.016s / 100iters, (0.000161)\n",
            "Loss_D = 0.04883379 (ave = 0.55565154)\n",
            "Loss_G = 3.91063118 (ave = 3.29512237)\n",
            "\n",
            "2019-02-24 09:44:20 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [17/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 150.005s / 100iters, (1.500)\tData load 0.016s / 100iters, (0.000158)\n",
            "Loss_D = 0.33370864 (ave = 0.55752217)\n",
            "Loss_G = 2.68264484 (ave = 3.40396518)\n",
            "\n",
            "2019-02-24 09:46:50 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [17/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 149.998s / 100iters, (1.500)\tData load 0.016s / 100iters, (0.000159)\n",
            "Loss_D = 0.54516149 (ave = 0.55968343)\n",
            "Loss_G = 1.88425469 (ave = 3.30819592)\n",
            "\n",
            "2019-02-24 09:49:20 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [17/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.162s / 69iters, (1.495)\tData load 0.011s / 69iters, (0.000159)\n",
            "Loss_D = 0.13145581 (ave = 0.54031239)\n",
            "Loss_G = 2.57183003 (ave = 3.31485141)\n",
            "\n",
            "2019-02-24 09:51:03 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [18/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.387s / 100iters, (1.514)\tData load 2.007s / 100iters, (0.020065)\n",
            "Loss_D = 0.01744778 (ave = 0.04823061)\n",
            "Loss_G = 4.72544575 (ave = 4.57375420)\n",
            "\n",
            "2019-02-24 09:53:34 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [18/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.868s / 100iters, (1.499)\tData load 0.015s / 100iters, (0.000154)\n",
            "Loss_D = 0.02177640 (ave = 0.03932905)\n",
            "Loss_G = 5.03427696 (ave = 4.80283284)\n",
            "\n",
            "2019-02-24 09:56:04 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [18/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 149.780s / 100iters, (1.498)\tData load 0.015s / 100iters, (0.000155)\n",
            "Loss_D = 0.03097415 (ave = 0.03370385)\n",
            "Loss_G = 7.14559221 (ave = 4.97839299)\n",
            "\n",
            "2019-02-24 09:58:34 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [18/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 149.866s / 100iters, (1.499)\tData load 0.016s / 100iters, (0.000157)\n",
            "Loss_D = 0.72235847 (ave = 0.26418794)\n",
            "Loss_G = 1.66185021 (ave = 4.44373906)\n",
            "\n",
            "2019-02-24 10:01:04 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [18/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.056s / 69iters, (1.494)\tData load 0.011s / 69iters, (0.000153)\n",
            "Loss_D = 0.41378859 (ave = 0.31010133)\n",
            "Loss_G = 4.65467405 (ave = 4.21105124)\n",
            "\n",
            "2019-02-24 10:02:47 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [19/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.638s / 100iters, (1.516)\tData load 2.063s / 100iters, (0.020627)\n",
            "Loss_D = 0.25491530 (ave = 0.63550700)\n",
            "Loss_G = 3.93924761 (ave = 3.16773322)\n",
            "\n",
            "2019-02-24 10:05:19 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [19/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.990s / 100iters, (1.500)\tData load 0.016s / 100iters, (0.000158)\n",
            "Loss_D = 0.66030473 (ave = 0.71222855)\n",
            "Loss_G = 1.81204057 (ave = 2.96525034)\n",
            "\n",
            "2019-02-24 10:07:49 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [19/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 149.884s / 100iters, (1.499)\tData load 0.016s / 100iters, (0.000162)\n",
            "Loss_D = 0.39325732 (ave = 0.69962277)\n",
            "Loss_G = 2.34732533 (ave = 2.95699049)\n",
            "\n",
            "2019-02-24 10:10:19 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [19/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 149.946s / 100iters, (1.499)\tData load 0.015s / 100iters, (0.000154)\n",
            "Loss_D = 0.06971753 (ave = 0.62929259)\n",
            "Loss_G = 2.54600906 (ave = 3.03201298)\n",
            "\n",
            "2019-02-24 10:12:48 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [19/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.237s / 69iters, (1.496)\tData load 0.011s / 69iters, (0.000154)\n",
            "Loss_D = 0.03264664 (ave = 0.54532157)\n",
            "Loss_G = 4.83517408 (ave = 3.23524001)\n",
            "\n",
            "2019-02-24 10:14:32 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [20/20] iteration: [100/469]\tLearning rate: 0.0002\n",
            "Time 151.429s / 100iters, (1.514)\tData load 2.053s / 100iters, (0.020530)\n",
            "Loss_D = 0.01816782 (ave = 0.02728625)\n",
            "Loss_G = 5.00304794 (ave = 4.99801802)\n",
            "\n",
            "2019-02-24 10:17:03 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [20/20] iteration: [200/469]\tLearning rate: 0.0002\n",
            "Time 149.749s / 100iters, (1.497)\tData load 0.016s / 100iters, (0.000158)\n",
            "Loss_D = 0.01160314 (ave = 0.02480222)\n",
            "Loss_G = 5.44349432 (ave = 5.15145773)\n",
            "\n",
            "2019-02-24 10:19:33 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [20/20] iteration: [300/469]\tLearning rate: 0.0002\n",
            "Time 149.704s / 100iters, (1.497)\tData load 0.016s / 100iters, (0.000156)\n",
            "Loss_D = 0.41282833 (ave = 0.34275759)\n",
            "Loss_G = 1.93027914 (ave = 4.19654193)\n",
            "\n",
            "2019-02-24 10:22:03 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [20/20] iteration: [400/469]\tLearning rate: 0.0002\n",
            "Time 149.653s / 100iters, (1.497)\tData load 0.016s / 100iters, (0.000158)\n",
            "Loss_D = 0.91718978 (ave = 0.40843939)\n",
            "Loss_G = 0.28815204 (ave = 3.84841052)\n",
            "\n",
            "2019-02-24 10:24:32 -----------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "epoch: [20/20] iteration: [469/469]\tLearning rate: 0.0002\n",
            "Time 103.086s / 69iters, (1.494)\tData load 0.011s / 69iters, (0.000157)\n",
            "Loss_D = 1.58831811 (ave = 0.44921605)\n",
            "Loss_G = 6.92224264 (ave = 3.73965309)\n",
            "\n",
            "2019-02-24 10:26:15 -----------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PkaiGzztbjYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###### latent variable에 따른 변화 확인\n",
        "\n",
        "model=network.generator(z_size=120, out_size=1) #pretrain할떄 120으로 지정, 흑백이므로 out 1\n",
        "checkpoint = torch.load('results/G_epoch_19.pth.tar')\n",
        "checkpoint.pop('epoch')\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rzp_4xurfBGf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noise = torch.randn(120).view(-1, 120, 1, 1)\n",
        "\n",
        "result=model(noise)\n",
        "image_size=64\n",
        "\n",
        "img = result.cpu().data.view(image_size, image_size).numpy()\n",
        "\n",
        "img.imshow(img, cmap='gray', aspect='equal')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pm0jYLqQiTFR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_result(G, fixed_noise, image_size, fig_size=(1, 8), is_gray=False):\n",
        "\n",
        "    G.eval()\n",
        "    generate_images = G(fixed_noise)\n",
        "    G.train()\n",
        "    \n",
        "    n_rows = 1\n",
        "    n_cols = 8\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=fig_size)\n",
        "    \n",
        "    for ax, img in zip(axes.flatten(), generate_images):\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "        if is_gray:\n",
        "            img = img.cpu().data.view(image_size, image_size).numpy()\n",
        "            ax.imshow(img, cmap='gray', aspect='equal')\n",
        "        else:\n",
        "            img = (((img - img.min()) * 255) / (img.max() - img.min())).cpu().data.numpy().transpose(1, 2, 0).astype(np.uint8)\n",
        "            ax.imshow(img, cmap=None, aspect='equal')\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    title = 'kamji' \n",
        "    fig.text(0.5, 0.04, title, ha='center')\n",
        "    \n",
        "    plt.savefig('kamji.png')\n",
        " \n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w2-_Z0N-ifAx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fixed_noise = torch.FloatTensor(120).normal_(0, 1)\n",
        "fixed_noise = fixed_noise.repeat(8,1).view([8,120,1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XW6I8zP7vCUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "63ab9a05-311d-42f3-8121-a9ed64ccb6b3"
      },
      "cell_type": "code",
      "source": [
        "fixed_noise[0:8,15,0,0]=torch.FloatTensor([-20,-10,-5,0,1,5,10,20])\n",
        "plot_result(model, fixed_noise, image_size=64, fig_size=(8, 8), is_gray=True)\n",
        "\n",
        "\n",
        "##3에서 8로 latent space에서의 한 축의 움직임에 따라 숫자 모양이 smooth하게 변화한다."
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py:1334: MatplotlibDeprecationWarning: \n",
            "box-forced\n",
            "  \"2.2\", \"box-forced\", obj_type=\"keyword argument\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}